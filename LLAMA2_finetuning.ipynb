{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKEVIN2010/LLMs-for-Dementia-Detection/blob/main/LLAMA2_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN2LJwLoAEhD"
      },
      "outputs": [],
      "source": [
        "import regex as re\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer, TrainingArguments, pipeline\n",
        "\n",
        "from trl import SFTTrainer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-etipB7AEhG"
      },
      "outputs": [],
      "source": [
        "def post_process(text):\n",
        "    text = text.strip()\n",
        "    text = text.lower()\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.replace(\" .\", \".\")\n",
        "    text = text.replace(\" ?\", \"?\")\n",
        "    text = text.replace(\"/.\", \"\")\n",
        "    text = text.replace(\"/\", \"\")\n",
        "    text = text.replace(\" ,\", \",\")\n",
        "    text = text.replace(\"//.\", \"\")\n",
        "    text = re.sub(r' +', ' ', text)\n",
        "    text = text.replace('\\\\', '')\n",
        "    return text\n",
        "\n",
        "ds = pd.read_csv(\"cookie.csv\")\n",
        "df = pd.DataFrame(columns=['text', 'label'], index=range(len(ds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdmJRNmnAEhH"
      },
      "outputs": [],
      "source": [
        "for i in range(len(ds)):\n",
        "    idx = ds.iat[i, 0]\n",
        "    text = ds.iat[i, 1]\n",
        "    label = ds.iat[i, 2]\n",
        "    text = post_process(text)\n",
        "    df.loc[i] = [text, label]\n",
        "\n",
        "split = int(len(df) * 0.8)\n",
        "df_train = df[:split]\n",
        "df_val = df[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIi9r2aGAEhI"
      },
      "outputs": [],
      "source": [
        "id_to_label = {0:'diseased subject', 1:'healthy subject'}\n",
        "template = \"### Human: The given speech transcript is either from a healthy subject or a diseased subject. Categorize it as one of them. \"\n",
        "train_instructions = [f\"{template}\\nTranscript: {x}\\n\\n ### Assistant: {id_to_label[y]}\" for x, y in zip(df_train.text, df_train.label)]\n",
        "val_instructions = [f\"{template}\\nTranscript: {x}\\n\\n ### Assistant: {id_to_label[y]}\" for x, y in zip(df_val.text, df_val.label)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN089iWSAEhJ"
      },
      "outputs": [],
      "source": [
        "ds_train = Dataset.from_dict({\"text\": train_instructions})\n",
        "ds_val = Dataset.from_dict({\"text\": val_instructions})\n",
        "instructions_ds_dict = DatasetDict({\"train\": ds_train, \"eval\": ds_val})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK5UCdVhAEhJ",
        "outputId": "0f9bba07-f02b-4925-c95d-abe190508972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Human: The given speech transcript is either from a healthy subject or a diseased subject. Categorize it as one of them. \n",
            "Transcript: well â€¡ the stool is falling over. the boy is taking cookies out of the cookie jar. the little girl is reaching for a cookie and holding her arm up. the mother is doing dishes. the water is spilling out of the sink. and the mothers standing in the water. the mother is looking out of the window. the waters coming out of the faucet. that is about all i can get out of that.\n",
            "\n",
            " ### Assistant: diseased subject\n"
          ]
        }
      ],
      "source": [
        "print(instructions_ds_dict['train']['text'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fppVVHCXAEhL",
        "outputId": "82e48f52-60d6-4640-beee-7fcda83ba9d4",
        "colab": {
          "referenced_widgets": [
            "4ddcbb125f8b4ef5b65cd74e6ef1d2cc"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ddcbb125f8b4ef5b65cd74e6ef1d2cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_id=\"meta-llama/Llama-2-7b-hf\"\n",
        "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
        "model = LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=False, device_map='auto', torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inafFFrAAEhL",
        "outputId": "9703ae92-df1c-449f-919f-0abf53ef96e6",
        "colab": {
          "referenced_widgets": [
            "8f4324555dc94c779b2751fb88a01f9e"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f4324555dc94c779b2751fb88a01f9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/441 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.train()\n",
        "\n",
        "peft_config = None\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./ft\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=1e-4,\n",
        "    logging_steps=10,\n",
        "    num_train_epochs=3,\n",
        "    max_steps=-1,\n",
        "    report_to=None,\n",
        "    save_steps=100,\n",
        "    save_total_limit=10,\n",
        "    push_to_hub=False,\n",
        "    hub_model_id=None,\n",
        "    bf16=True,  # Use BF16 if available\n",
        "    optim=\"adamw_torch_fused\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    max_seq_length=512,\n",
        "    train_dataset=instructions_ds_dict['train'],\n",
        "    dataset_text_field=\"text\",\n",
        "    peft_config=peft_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRwty5FsAEhM",
        "outputId": "8e5bc71a-4f02-4cc3-9633-cf3ff4d72e89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [330/330 03:54, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.454800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.730600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.781000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.603600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.547400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.677300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.630500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.655400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.559800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.584900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.537100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.132100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.084300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.987700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.102200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.989100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.042000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.038800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.022400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.968100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.619400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.488400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.464700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.421300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.402100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.446700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.444200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.413400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.445500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.441800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.437800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()\n",
        "model.save_pretrained(training_args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezu0CtS4AEhM",
        "outputId": "e2e24b22-aeec-4b01-d805-541b7f08892d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMglBheJAEhN"
      },
      "outputs": [],
      "source": [
        "queries = [instructions_ds_dict['eval']['text'][i].split('### Assistant: ')[0] + '### Assistant:' for i in range(len(instructions_ds_dict['eval']))]\n",
        "sequences = pipeline(\n",
        "    queries,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_new_tokens=3,\n",
        "    early_stopping=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5krSqQ2uAEhO",
        "outputId": "3fc8085e-acba-44f7-d5df-ce7afdafd598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8018018018018018\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for seq in sequences:\n",
        "  result = seq[0]['generated_text'].split('### Assistant:')[1]\n",
        "  results.append(result)\n",
        "\n",
        "labels = []\n",
        "for label in instructions_ds_dict['eval']['text']:\n",
        "  result = label.split('### Assistant:')[1]\n",
        "  labels.append(result)\n",
        "\n",
        "print(\"Accuracy: \", (len([1 for x, y in zip(results, labels) if y in x]) / len(labels)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}