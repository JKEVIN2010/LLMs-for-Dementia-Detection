{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKEVIN2010/LLMs-for-Dementia-Detection/blob/main/Dementia_GPT_2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "179435ce",
      "metadata": {
        "id": "179435ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
        "from transformers import TextDataset, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, TextDataset, DataCollatorWithPadding, Trainer, TrainingArguments\n",
        "import re\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25864e21",
      "metadata": {
        "id": "25864e21"
      },
      "outputs": [],
      "source": [
        "class DementiaTextDataset(Dataset):\n",
        "    def __init__(self, encodings, labels, block_size=384):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.encodings[\"input_ids\"][idx][:self.block_size]\n",
        "        attention_mask = self.encodings[\"attention_mask\"][idx][:self.block_size]\n",
        "\n",
        "        # Pad the input_ids and attention_mask if needed\n",
        "        padding_length = max(0, self.block_size - len(input_ids))\n",
        "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
        "        attention_mask = attention_mask + [0] * padding_length\n",
        "\n",
        "        item = {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask)}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40083f2d",
      "metadata": {
        "id": "40083f2d"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess your data\n",
        "def load_data(dementia_file_path, non_dementia_file_path):\n",
        "    with open(dementia_file_path, 'r') as file:\n",
        "        dementia_data = file.readlines()\n",
        "    with open(non_dementia_file_path, 'r') as file:\n",
        "        non_dementia_data = file.readlines()\n",
        "\n",
        "    data = {\n",
        "        \"text\": dementia_data + non_dementia_data,\n",
        "        \"label\": [1] * len(dementia_data) + [0] * len(non_dementia_data),\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcef78a4",
      "metadata": {
        "id": "bcef78a4"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert the text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05cbbdec",
      "metadata": {
        "id": "05cbbdec"
      },
      "outputs": [],
      "source": [
        "dementia_file_path = \"dementia_samples.txt\"\n",
        "non_dementia_file_path = \"non_dementia_samples.txt\"\n",
        "df = load_data(dementia_file_path, non_dementia_file_path)\n",
        "\n",
        "# Visualize labeled data\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac38394",
      "metadata": {
        "id": "2ac38394",
        "outputId": "372edae2-caa5-4906-adf9-d1d7ec6e7a89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mhm   alright   there is a young boy that is g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mhm   there is a young boy going in a cookie j...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>heres a cookie jar   and the lid is off the co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the boy is slipping off the stool   he is tryi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>okay he is falling off a stool   she is runnin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>well the little girl is reaching for a cookie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>mhm   mhm a lot of things are happening   yes ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>alright   the little girls reaching up there a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>okay   well in the first place the mother forg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>the mother is drying the dishes   and the fauc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>552 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  label\n",
              "0    mhm   alright   there is a young boy that is g...      1\n",
              "1    mhm   there is a young boy going in a cookie j...      1\n",
              "2    heres a cookie jar   and the lid is off the co...      1\n",
              "3    the boy is slipping off the stool   he is tryi...      1\n",
              "4    okay he is falling off a stool   she is runnin...      1\n",
              "..                                                 ...    ...\n",
              "547  well the little girl is reaching for a cookie ...      0\n",
              "548  mhm   mhm a lot of things are happening   yes ...      0\n",
              "549  alright   the little girls reaching up there a...      0\n",
              "550  okay   well in the first place the mother forg...      0\n",
              "551  the mother is drying the dishes   and the fauc...      0\n",
              "\n",
              "[552 rows x 2 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Clean data and visualize it\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c323a0e",
      "metadata": {
        "id": "5c323a0e",
        "outputId": "da5718fe-2603-439c-e9f9-eae294eee530"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Initialize GPT-2 tokenizer and model\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Adding padding token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Labels\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
        "train_texts = train_texts.reset_index(drop=True)\n",
        "val_texts = val_texts.reset_index(drop=True)\n",
        "train_labels = train_labels.to_list()\n",
        "val_labels = val_labels.to_list()\n",
        "\n",
        "\n",
        "block_size = 384\n",
        "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=block_size)\n",
        "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=block_size)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = DementiaTextDataset(train_encodings, train_labels)\n",
        "val_dataset = DementiaTextDataset(val_encodings, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28de1584",
      "metadata": {
        "id": "28de1584"
      },
      "outputs": [],
      "source": [
        "# Define training arguments and instantiate Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./GPT_results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f301ed6",
      "metadata": {
        "id": "5f301ed6",
        "outputId": "8bc3a2f6-b0b8-4ba5-90b4-46eca13de5f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kxm5924/PycharmProjects/pythonProject/venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [168/168 51:47, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.923800</td>\n",
              "      <td>0.542902</td>\n",
              "      <td>0.729730</td>\n",
              "      <td>0.843137</td>\n",
              "      <td>0.661538</td>\n",
              "      <td>0.741379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.606300</td>\n",
              "      <td>0.463180</td>\n",
              "      <td>0.765766</td>\n",
              "      <td>0.791045</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>0.803030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.428000</td>\n",
              "      <td>0.481881</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.787879</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.793893</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14/14 00:49]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.46317964792251587, 'eval_accuracy': 0.7657657657657657, 'eval_precision': 0.7910447761194029, 'eval_recall': 0.8153846153846154, 'eval_f1': 0.803030303030303, 'eval_runtime': 53.6049, 'eval_samples_per_second': 2.071, 'eval_steps_per_second': 0.261, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9cf350",
      "metadata": {
        "id": "bf9cf350"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"dementia_gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bafc8b75",
      "metadata": {
        "id": "bafc8b75"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}