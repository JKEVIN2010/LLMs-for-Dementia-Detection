{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKEVIN2010/LLMs-for-Dementia-Detection/blob/main/LLAMA2_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gklWcm8AYje"
      },
      "outputs": [],
      "source": [
        "import regex as re\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer, pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFZMBCxGAYjk"
      },
      "outputs": [],
      "source": [
        "def post_process(text):\n",
        "    text = text.strip()\n",
        "    text = text.lower()\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.replace(\" .\", \".\")\n",
        "    text = text.replace(\" ?\", \"?\")\n",
        "    text = text.replace(\"/.\", \"\")\n",
        "    text = text.replace(\"/\", \"\")\n",
        "    text = text.replace(\" ,\", \",\")\n",
        "    text = text.replace(\"//.\", \"\")\n",
        "    text = re.sub(r' +', ' ', text)\n",
        "    text = text.replace('\\\\', '')\n",
        "    return text\n",
        "\n",
        "ds = pd.read_csv(\"cookie.csv\")\n",
        "df = pd.DataFrame(columns=['text', 'label'], index=range(len(ds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-xsJ-e2AYjm"
      },
      "outputs": [],
      "source": [
        "for i in range(len(ds)):\n",
        "    idx = ds.iat[i, 0]\n",
        "    text = ds.iat[i, 1]\n",
        "    label = ds.iat[i, 2]\n",
        "    text = post_process(text)\n",
        "    df.loc[i] = [text, label]\n",
        "\n",
        "split = int(len(df) * 0.8)\n",
        "df_train = df[:split]\n",
        "df_val = df[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1WfIBBhAYjm"
      },
      "outputs": [],
      "source": [
        "id_to_label = {0:'diseased subject', 1:'healthy subject'}\n",
        "template = \"### Human: The given speech transcript is either from a healthy subject or a diseased subject. Categorize it as one of them. \"\n",
        "train_instructions = [f\"{template}\\nTranscript: {x}\\n\\n ### Assistant: {id_to_label[y]}\" for x, y in zip(df_train.text, df_train.label)]\n",
        "val_instructions = [f\"{template}\\nTranscript: {x}\\n\\n ### Assistant: {id_to_label[y]}\" for x, y in zip(df_val.text, df_val.label)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIHtiKu-AYjn"
      },
      "outputs": [],
      "source": [
        "ds_train = Dataset.from_dict({\"text\": train_instructions})\n",
        "ds_val = Dataset.from_dict({\"text\": val_instructions})\n",
        "instructions_ds_dict = DatasetDict({\"train\": ds_train, \"eval\": ds_val})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIllRa-PAYjo",
        "outputId": "a2a6c056-21d7-4337-85e3-d8c084b8596a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Human: The given speech transcript is either from a healthy subject or a diseased subject. Categorize it as one of them. \n",
            "Transcript: well â€¡ the stool is falling over. the boy is taking cookies out of the cookie jar. the little girl is reaching for a cookie and holding her arm up. the mother is doing dishes. the water is spilling out of the sink. and the mothers standing in the water. the mother is looking out of the window. the waters coming out of the faucet. that is about all i can get out of that.\n",
            "\n",
            " ### Assistant: diseased subject\n"
          ]
        }
      ],
      "source": [
        "print(instructions_ds_dict['train']['text'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB7KeQGuAYjp",
        "outputId": "41ec864a-20f1-465f-e3c1-3d2a21849e06",
        "colab": {
          "referenced_widgets": [
            "b03c5b43cc384e59913c280a427504ef"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b03c5b43cc384e59913c280a427504ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
        "model = LlamaForCausalLM.from_pretrained(\"./ft\", load_in_8bit=False, device_map='auto', torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDYFLGLKAYjq",
        "outputId": "ddc25f64-a2d0-455d-9acc-769c601c6c89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wbhy3xHhAYjr"
      },
      "outputs": [],
      "source": [
        "queries = [instructions_ds_dict['eval']['text'][i].split('### Assistant: ')[0] + '### Assistant:' for i in range(len(instructions_ds_dict['eval']))]\n",
        "sequences = pipeline(\n",
        "    queries,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_new_tokens=3,\n",
        "    early_stopping=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0MHxPlIAYjr",
        "outputId": "4f756b99-fdeb-46b0-c7c8-42b46a27710c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8018018018018018\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for seq in sequences:\n",
        "  result = seq[0]['generated_text'].split('### Assistant:')[1]\n",
        "  results.append(result)\n",
        "\n",
        "labels = []\n",
        "for label in instructions_ds_dict['eval']['text']:\n",
        "  result = label.split('### Assistant:')[1]\n",
        "  labels.append(result)\n",
        "\n",
        "print(\"Accuracy: \", (len([1 for x, y in zip(results, labels) if y in x]) / len(labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujXQ3rhjAYjt"
      },
      "outputs": [],
      "source": [
        "results_idx = []\n",
        "for result in results:\n",
        "  if 'healthy' in result:\n",
        "    results_idx.append(1)\n",
        "  else:\n",
        "    results_idx.append(0)\n",
        "\n",
        "labels_idx = []\n",
        "for label in labels:\n",
        "  if 'healthy' in label:\n",
        "    labels_idx.append(1)\n",
        "  else:\n",
        "    labels_idx.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzXqpr5zAYju"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(results_idx, labels_idx).ravel()\n",
        "specificity = tn / (tn+fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVQKRxIgAYju",
        "outputId": "bd380e1b-14cb-40a6-cdc3-0a92a1ac59ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:           0.8018\n",
            "F1 Score:           0.8281\n",
            "Precision:          0.9138\n",
            "Specificity:        0.8780\n",
            "Recall/Sensitivity: 0.7571\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:           {:.4f}\".format(accuracy_score(results_idx, labels_idx)))\n",
        "print(\"F1 Score:           {:.4f}\".format(f1_score(results_idx, labels_idx)))\n",
        "print(\"Precision:          {:.4f}\".format(precision_score(results_idx, labels_idx)))\n",
        "print(\"Specificity:        {:.4f}\".format(specificity))\n",
        "print(\"Recall/Sensitivity: {:.4f}\".format(recall_score(results_idx, labels_idx)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}